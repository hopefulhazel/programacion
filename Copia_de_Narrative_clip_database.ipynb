{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copia de Narrative clip database.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "EgMkYy4PfDFY"
      ],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hopefulhazel/programacion/blob/master/Copia_de_Narrative_clip_database.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrdIt8H1QLaC",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hiq5rB1td3X2",
        "colab": {}
      },
      "source": [
        "# Cargamos la versión 2.x de TensorFlow\n",
        "try:\n",
        "  # %tensorflow_version sólo existe en Colab\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBAf-UBmiETN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWz3kuN39LJd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://ub.panalsoft.com/labeling/public/api/photos/download-csv -O /content/drive/My\\ Drive/database/database.csv\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vlCL2Gw4dS8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "img=mpimg.imread('/content/drive/My Drive/database/photos/_g4/42770/conversions/172445-thumb.jpg')\n",
        "imgplot = plt.imshow(img)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcRpw0L9V0lL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importing pandas package\n",
        "import pandas as pd\n",
        " \n",
        "# making data frame from csv file\n",
        "df = pd.read_csv(\"/content/drive/My Drive/database/database.csv\")\n",
        "print(df.head(5))\n",
        "\n",
        "df['path'] = \"/content/drive/My Drive/database/photos/\" + \"_g\" + df.media_id.map(str).map(lambda x: x[:1]) + \"/\" + df.media_id.map(str) + \"/conversions/\" + df.filename.map(lambda x: x[:-4]) + \"-thumb.jpg\"\n",
        "df = df[['path', 'label']]\n",
        "df['path'] = df['path'].astype(str)\n",
        "\n",
        "# remove labels with a lot of rows\n",
        "df_filter = df['label'] != 'Using a Computer'\n",
        "df = df[df_filter]\n",
        "\n",
        "# ramdom sorting the dataframe\n",
        "df = df.sample(frac=1)\n",
        "\n",
        "TO_TEST = 100\n",
        "df_test = df.head(TO_TEST)\n",
        "\n",
        "#df = df.tail(len(df) - TO_TEST)\n",
        "df = df.tail(10000 - TO_TEST)\n",
        "\n",
        "print(df.head(5))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwauP0CnxL_s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.label.value_counts().plot(kind=\"bar\", figsize=(15,8))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dofu2uVrdctr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importamos TensorFlow y tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Importamos algunas librerías de apoyo como numpy y matplot\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
        "import pathlib\n",
        "\n",
        "EPOCHS = 10\n",
        "BATCH_SIZE = 8\n",
        "LR = 2e-5\n",
        "IMGW = 299\n",
        "IMGH = 299\n",
        "IMGN = 255\n",
        "\n",
        "#datagen = ImageDataGenerator(rescale = 1.0 / IMGN)\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale = 1. / IMGN,\n",
        "    #rotation_range = 90,\n",
        "    #width_shift_range = 0.2,\n",
        "    #height_shift_range = 0.2,\n",
        "    #shear_range = 0.2,\n",
        "    #zoom_range = 0.2,\n",
        "    #horizontal_flip = True,\n",
        "    #fill_mode = 'nearest',\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "\n",
        "train_images = datagen.flow_from_dataframe(\n",
        "    dataframe=df, \n",
        "    directory=None, \n",
        "    x_col=\"path\", \n",
        "    y_col=\"label\", \n",
        "    class_mode=\"categorical\", \n",
        "    target_size = (IMGW, IMGH),\n",
        "    batch_size = BATCH_SIZE,\n",
        "    subset=\"training\"\n",
        ")\n",
        "\n",
        "validation_images = datagen.flow_from_dataframe(\n",
        "    dataframe=df, \n",
        "    directory=None, \n",
        "    x_col=\"path\", \n",
        "    y_col=\"label\", \n",
        "    class_mode=\"categorical\", \n",
        "    target_size = (IMGW, IMGH),\n",
        "    batch_size = BATCH_SIZE,\n",
        "    subset=\"validation\"\n",
        ")\n",
        "\n",
        "CLASSES = 24\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqoQLuZU7pF4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CLASSES = 23"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Js9xi7C6QRvY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import applications, optimizers\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "base_model = applications.inception_resnet_v2.InceptionResNetV2(include_top=False, weights='imagenet', input_shape=(IMGW, IMGH, 3))\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "model.add(base_model)\n",
        "\n",
        "TRAINABLE_LAYERS = 1\n",
        "\n",
        "for layer in base_model.layers[:-TRAINABLE_LAYERS]:\n",
        "    layer.trainable=False\n",
        "\n",
        "for layer in base_model.layers[-TRAINABLE_LAYERS:]:\n",
        "    layer.trainable=True\n",
        "\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(CLASSES, activation='softmax'))\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(lr=LR), metrics=[\"accuracy\"])\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNAH13ZTR9s-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history_transfer = model.fit(\n",
        "  train_images, \n",
        "  #batch_size = BATCH_SIZE, \n",
        "  epochs = EPOCHS, \n",
        "  #verbose = 2, \n",
        "  #callbacks = None, \n",
        "  validation_data = validation_images, \n",
        "  #class_weight = None, \n",
        "  #sample_weight=None, \n",
        "  #steps_per_epoch=None, \n",
        "  #validation_steps=None, \n",
        "  #workers=1, \n",
        "  #use_multiprocessing = True,\n",
        "  shuffle = True\n",
        ")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDYyzPEPe8Sk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot training & validation accuracy values\n",
        "plt.plot(history_transfer.history['accuracy'])\n",
        "plt.plot(history_transfer.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history_transfer.history['loss'])\n",
        "plt.plot(history_transfer.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgdWglQ6a-0X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "Y_pred = model.predict_generator(validation_images, CLASSES // BATCH_SIZE+1)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "\n",
        "print(confusion_matrix(validation_images.classes, y_pred))\n",
        "#print(confusion_matrix(validation_images.classes, y_pred, df.label_name.unique()))\n",
        "\n",
        "#print('Classification Report')\n",
        "#target_names = ['Dishwashing', 'Using a Computer']\n",
        "#print(classification_report(validation_images.classes, y_pred, target_names=target_names))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcW6esuC-N2q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('/content/drive/My Drive/database/model1.h5')\n",
        "\n",
        "# Exportar el modelo a 'SavedModel'\n",
        "#keras.experimental.export_saved_model(model, '/content/drive/My Drive/database/model1')\n",
        "\n",
        "# Recrea exactamente el mismo modelo\n",
        "#new_model = keras.experimental.load_from_saved_model('/content/drive/My Drive/database/model1')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpLkhzok-qP0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_model = keras.models.load_model('/content/drive/My Drive/database/model1.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTSmwrXx_mxI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "from io import BytesIO\n",
        "from urllib.request import urlopen\n",
        "\n",
        "labels = (train_images.class_indices)\n",
        "labels = dict((v,k) for k,v in labels.items())\n",
        "\n",
        "def predict(model, image_url):\n",
        "#  img = load_img(f, target_size=(hyperparams[\"img_width\"], hyperparams[\"img_height\"]))\n",
        "\n",
        "  with urlopen(image_url) as url:\n",
        "    url_read = BytesIO(url.read())\n",
        "    img_original = load_img(url_read)\n",
        "    img = load_img(url_read, target_size=(299, 299))\n",
        "\n",
        "  img = img_to_array(img)\n",
        "  img = np.expand_dims(img, axis=0)\n",
        "\n",
        "  plt.imshow(img_original)\n",
        "  plt.show()\n",
        "\n",
        "  img = datagen.standardize(img)\n",
        "\n",
        "  res = model.predict(img)  \n",
        "  print(\"predicts: \" + labels[np.argmax(res)])  \n",
        "\n",
        "  res = np.around(res[0], decimals=2)  \n",
        "  print(res)\n",
        "  print('--------------------')\n",
        "\n",
        "  return res\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81OgJSOASHiB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict(new_model, 'https://s3.amazonaws.com/ub.labeling/72936/conversions/114249-thumb.jpg')\n",
        "predict(new_model, 'https://s3.amazonaws.com/ub.labeling/92932/conversions/145453-thumb.jpg')\n",
        "predict(new_model, 'https://images.wsj.net/im-112660?width=620&size=1.5')\n",
        "predict(new_model, 'https://article.images.consumerreports.org/f_auto/prod/content/dam/CRO%20Images%202019/Health/01January/CR-Health-InlineHero-Get-Biggest-Benefits-of-Walking-01-19-v2')\n",
        "predict(new_model, 'https://image.shutterstock.com/image-photo/modern-business-people-walking-on-260nw-739813360.jpg')\n",
        "\n",
        "print('')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}